"""
CRAG (Corrective RAG) ì „ëµ í…ŒìŠ¤íŠ¸
"""

import sys
import os
import pytest

if not os.getenv("OPENAI_API_KEY") or not os.getenv("TAVILY_API_KEY"):
    pytest.skip(
        "CRAG í…ŒìŠ¤íŠ¸ëŠ” OpenAI ë° Tavily API í‚¤ê°€ í•„ìš”í•˜ì—¬ í‚¤ê°€ ì—†ìœ¼ë©´ ê±´ë„ˆëœë‹ˆë‹¤.",
        allow_module_level=True,
    )

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from langchain_core.documents import Document
from src.strategies import create_corrective_rag, CRAGAction


def create_sample_documents(relevant: int, irrelevant: int) -> list:
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë¬¸ì„œ ìƒì„±"""
    docs = []

    # ê´€ë ¨ ìˆëŠ” ë¬¸ì„œ
    for i in range(relevant):
        docs.append(
            Document(
                page_content=f"""
            ëŒ€ì‚¬ì¦í›„êµ° ê´€ë ¨ ì •ë³´ {i+1}:
            ëŒ€ì‚¬ì¦í›„êµ°ì€ ë³µë¶€ ë¹„ë§Œ, ê³ í˜ˆì••, ê³ í˜ˆë‹¹, ì´ìƒì§€ì§ˆí˜ˆì¦ ë“±ì´ 
            ë³µí•©ì ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” ìƒíƒœì…ë‹ˆë‹¤. ì§„ë‹¨ ê¸°ì¤€ì€ 5ê°€ì§€ í•­ëª© ì¤‘ 
            3ê°€ì§€ ì´ìƒì„ ì¶©ì¡±í•  ë•Œì…ë‹ˆë‹¤.
            """,
                metadata={"doc_id": f"relevant_{i+1}"},
            )
        )

    # ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œ
    for i in range(irrelevant):
        docs.append(
            Document(
                page_content=f"""
            ë¬´ê´€í•œ ì •ë³´ {i+1}:
            ê°ê¸°ëŠ” ë°”ì´ëŸ¬ìŠ¤ ê°ì—¼ìœ¼ë¡œ ì¸í•œ ìƒê¸°ë„ ê°ì—¼ì…ë‹ˆë‹¤.
            ì£¼ìš” ì¦ìƒìœ¼ë¡œëŠ” ì½§ë¬¼, ê¸°ì¹¨, ì¸í›„í†µ ë“±ì´ ìˆìŠµë‹ˆë‹¤.
            """,
                metadata={"doc_id": f"irrelevant_{i+1}"},
            )
        )

    return docs


def test_correct_action():
    """CORRECT ì•¡ì…˜ í…ŒìŠ¤íŠ¸ (ì¶©ë¶„í•œ ê´€ë ¨ ë¬¸ì„œ)"""
    print("=" * 60)
    print("CORRECT ì•¡ì…˜ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    crag = create_corrective_rag(min_relevant_docs=2)
    query = "ëŒ€ì‚¬ì¦í›„êµ°ì˜ ì§„ë‹¨ ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?"

    # ê´€ë ¨ ë¬¸ì„œ 4ê°œ (ì¶©ë¶„í•¨)
    documents = create_sample_documents(relevant=4, irrelevant=0)

    print(f"\nì§ˆë¬¸: {query}")
    print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(documents)}ê°œ")

    result = crag.execute(query, documents)

    print(f"\nì•¡ì…˜: {result.action.value}")
    print(f"ì´ìœ : {result.reason}")
    print(f"ì›¹ ê²€ìƒ‰ ìˆ˜í–‰: {result.web_search_performed}")
    print(f"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {result.original_doc_count}ê°œ")
    print(f"ìµœì¢… ë¬¸ì„œ ìˆ˜: {result.final_doc_count}ê°œ")

    assert result.action == CRAGAction.CORRECT
    assert not result.web_search_performed
    print("\nâœ… CORRECT ì•¡ì…˜ í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_incorrect_action():
    """INCORRECT ì•¡ì…˜ í…ŒìŠ¤íŠ¸ (ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ)"""
    print("\n" + "=" * 60)
    print("INCORRECT ì•¡ì…˜ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    crag = create_corrective_rag(min_relevant_docs=2)
    query = "ëŒ€ì‚¬ì¦í›„êµ°ì˜ ì§„ë‹¨ ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?"

    # ê´€ë ¨ ë¬¸ì„œ 0ê°œ (ëª¨ë‘ ë¬´ê´€í•¨)
    documents = create_sample_documents(relevant=0, irrelevant=3)

    print(f"\nì§ˆë¬¸: {query}")
    print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(documents)}ê°œ")

    result = crag.execute(query, documents)

    print(f"\nì•¡ì…˜: {result.action.value}")
    print(f"ì´ìœ : {result.reason}")
    print(f"ì›¹ ê²€ìƒ‰ ìˆ˜í–‰: {result.web_search_performed}")
    print(f"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {result.original_doc_count}ê°œ")
    print(f"ìµœì¢… ë¬¸ì„œ ìˆ˜: {result.final_doc_count}ê°œ")

    if result.final_doc_count > 0:
        print(f"\nì›¹ ê²€ìƒ‰ ê²°ê³¼ ìƒ˜í”Œ:")
        for i, doc in enumerate(result.documents[:2], 1):
            print(f"  ë¬¸ì„œ {i}: {doc.metadata.get('title', 'N/A')[:50]}...")

    assert result.action == CRAGAction.INCORRECT
    assert result.web_search_performed
    print("\nâœ… INCORRECT ì•¡ì…˜ í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_ambiguous_action():
    """AMBIGUOUS ì•¡ì…˜ í…ŒìŠ¤íŠ¸ (ì¼ë¶€ë§Œ ê´€ë ¨)"""
    print("\n" + "=" * 60)
    print("AMBIGUOUS ì•¡ì…˜ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    crag = create_corrective_rag(min_relevant_docs=2)
    query = "ëŒ€ì‚¬ì¦í›„êµ°ì˜ ì§„ë‹¨ ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?"

    # ê´€ë ¨ ë¬¸ì„œ 1ê°œ (ë¶ˆì¶©ë¶„), ë¬´ê´€ ë¬¸ì„œ 2ê°œ
    documents = create_sample_documents(relevant=1, irrelevant=2)

    print(f"\nì§ˆë¬¸: {query}")
    print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(documents)}ê°œ")

    result = crag.execute(query, documents)

    print(f"\nì•¡ì…˜: {result.action.value}")
    print(f"ì´ìœ : {result.reason}")
    print(f"ì›¹ ê²€ìƒ‰ ìˆ˜í–‰: {result.web_search_performed}")
    print(f"ì›ë³¸ ë¬¸ì„œ ìˆ˜: {result.original_doc_count}ê°œ")
    print(f"ìµœì¢… ë¬¸ì„œ ìˆ˜: {result.final_doc_count}ê°œ")

    # ìµœì¢… ë¬¸ì„œ ì†ŒìŠ¤ ë¶„ì„
    internal_count = sum(
        1
        for doc in result.documents
        if doc.metadata.get("source") != "tavily_web_search"
    )
    web_count = sum(
        1
        for doc in result.documents
        if doc.metadata.get("source") == "tavily_web_search"
    )

    print(f"\nìµœì¢… ë¬¸ì„œ êµ¬ì„±:")
    print(f"  ë‚´ë¶€ ë¬¸ì„œ: {internal_count}ê°œ")
    print(f"  ì›¹ ë¬¸ì„œ: {web_count}ê°œ")

    assert result.action == CRAGAction.AMBIGUOUS
    assert result.web_search_performed
    assert web_count > 0  # ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ í¬í•¨ë˜ì–´ì•¼ í•¨
    print("\nâœ… AMBIGUOUS ì•¡ì…˜ í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_empty_documents():
    """ë¹ˆ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ë¹ˆ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    crag = create_corrective_rag()
    query = "ëŒ€ì‚¬ì¦í›„êµ°ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"
    documents = []

    print(f"\nì§ˆë¬¸: {query}")
    print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(documents)}ê°œ")

    result = crag.execute(query, documents)

    print(f"\nì•¡ì…˜: {result.action.value}")
    print(f"ì´ìœ : {result.reason}")
    print(f"ì›¹ ê²€ìƒ‰ ìˆ˜í–‰: {result.web_search_performed}")
    print(f"ìµœì¢… ë¬¸ì„œ ìˆ˜: {result.final_doc_count}ê°œ")

    assert result.action == CRAGAction.INCORRECT
    assert result.web_search_performed
    print("\nâœ… ë¹ˆ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸ í†µê³¼")


def test_document_refinement():
    """ë¬¸ì„œ ì •ì œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ë¬¸ì„œ ì •ì œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    crag = create_corrective_rag(min_relevant_docs=2)
    query = "ëŒ€ì‚¬ì¦í›„êµ°ì˜ ì§„ë‹¨ ê¸°ì¤€ì€?"

    # ê´€ë ¨ 3ê°œ + ë¬´ê´€ 2ê°œ
    documents = create_sample_documents(relevant=3, irrelevant=2)

    print(f"\nì§ˆë¬¸: {query}")
    print(f"ì›ë³¸ ë¬¸ì„œ: {len(documents)}ê°œ")

    result = crag.execute(query, documents)

    print(f"\nì•¡ì…˜: {result.action.value}")
    print(f"ì •ì œ í›„ ë¬¸ì„œ: {result.final_doc_count}ê°œ")

    # ë¬´ê´€í•œ ë¬¸ì„œê°€ ì œê±°ë˜ì—ˆëŠ”ì§€ í™•ì¸
    irrelevant_docs = [
        doc
        for doc in result.documents
        if "irrelevant" in doc.metadata.get("doc_id", "")
    ]

    print(f"ì œê±°ëœ ë¬´ê´€ ë¬¸ì„œ: {2 - len(irrelevant_docs)}ê°œ")

    assert result.action == CRAGAction.CORRECT
    assert len(irrelevant_docs) < 2  # ì¼ë¶€ ë¬´ê´€ ë¬¸ì„œê°€ ì œê±°ë˜ì–´ì•¼ í•¨
    print("\nâœ… ë¬¸ì„œ ì •ì œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼")


if __name__ == "__main__":
    print("\nğŸ” CRAG ì „ëµ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")

    try:
        test_correct_action()
        test_incorrect_action()
        test_ambiguous_action()
        test_empty_documents()
        test_document_refinement()

        print("\n" + "=" * 60)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback

        traceback.print_exc()
